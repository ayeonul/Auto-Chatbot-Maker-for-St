{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import ChatbotMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eca8b054f74b465a89a33d27863cd5ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2a463c782474408a3e940d563fe3c24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4f9ef83606840f98bc170b211ed0b05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<utils.ChatbotMaker at 0x276456a6910>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [\n",
    "    {\n",
    "        \"code\": \"1\",\n",
    "        \"title\": \"NCSë€\",\n",
    "        \"url\": [\"https://ncs.go.kr/th01/TH-102-001-01.scdo\"],\n",
    "    },\n",
    "    {\n",
    "        \"code\": \"1.1\",\n",
    "        \"title\": \"NCS ë¶„ë¥˜\",\n",
    "        \"url\": [\"https://ncs.go.kr/th01/TH-102-001-02.scdo\"],\n",
    "    },\n",
    "    {\n",
    "        \"code\": \"1.3\",\n",
    "        \"title\": \"NCS êµ¬ì„±\",\n",
    "        \"url\": [\"https://ncs.go.kr/th01/TH-102-001-03.scdo\"],\n",
    "    },\n",
    "    {\n",
    "        \"code\": \"1.4\",\n",
    "        \"title\": \"NCS ì—°í˜\",\n",
    "        \"url\": [\"https://ncs.go.kr/th01/TH-102-001-04.scdo\"],\n",
    "    },\n",
    "    {\n",
    "        \"code\": \"2\",\n",
    "        \"title\": \"NCS í•™ìŠµëª¨ë“ˆì´ë€\",\n",
    "        \"url\": [\"https://ncs.go.kr/th01/TH-102-002-01.scdo\"],\n",
    "    },\n",
    "    {\n",
    "        \"code\": \"2.1\",\n",
    "        \"title\": \"NCS í•™ìŠµëª¨ë“ˆì˜ êµ¬ì„±\",\n",
    "        \"url\": [\n",
    "            \"https://ncs.go.kr/th01/TH-102-002-02.scdo\",\n",
    "            \"https://ncs.go.kr/th01/TH-102-002-03.scdo\",\n",
    "            \"https://ncs.go.kr/th01/TH-102-002-04.scdo\",\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"code\": \"2.2\",\n",
    "        \"title\": \"NCS í•™ìŠµëª¨ë“ˆì˜ í™œìš©\",\n",
    "        \"url\": [\"https://ncs.go.kr/th01/TH-102-002-07.scdo\"],\n",
    "    },\n",
    "]\n",
    "\n",
    "greeting_text = \"ì•ˆë…•í•˜ì„¸ìš”ğŸ˜Š ì €ëŠ” NCS í™ˆí˜ì´ì§€ ì•ˆë‚´ ì±—ë´‡ì´ì—ìš”! NCS í™ˆí˜ì´ì§€ì— ëŒ€í•´ì„œ ì•Œë ¤ë“œë¦´ê²Œìš”! ê¶ê¸ˆí•œ ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì‹œë©´ ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•´ë“œë¦´ê²Œìš”ğŸ˜‰\"\n",
    "\n",
    "ChatbotMaker(\n",
    "    model_name=\"gpt-4-1106-preview\", chatbot_name=\"NCS í™ˆí˜ì´ì§€ ì•ˆë‚´ ì±—ë´‡\", sitemap=data, greeting_text=greeting_text\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from engine.search import Search\n",
    "from engine.encoder import Encoder\n",
    "import os\n",
    "from utils import ChatbotData, ChatbotEngine\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_KEY = os.getenv(\"OPENAI_KEY\")\n",
    "MIN_INFERENCE_BOUND = float(os.getenv(\"MIN_INFERENCE_BOUND\"))\n",
    "MAX_INFERENCE_BOUND = float(os.getenv(\"MAX_INFERENCE_BOUND\"))\n",
    "PORT = int(os.getenv(\"PORT\"))\n",
    "MULTI_INTENTS_TEXT = os.getenv(\"MULTI_INTENTS_TEXT\")\n",
    "FALLBACK_TEXT = os.getenv(\"FALLBACK_TEXT\")\n",
    "ERROR_TEXT = os.getenv(\"ERROR_TEXT\")\n",
    "\n",
    "encoder = Encoder()\n",
    "chatbot_data = ChatbotData(encoder)\n",
    "engine = Search(chatbot_data.example_embs[[\"emb\"]], chatbot_data.example_embs[[\"code\"]])\n",
    "\n",
    "\n",
    "chatbot_engine = ChatbotEngine(encoder, engine, chatbot_data.chatbot_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'code': '0',\n",
       " 'title': 'ì¸ì‚¬ë§(main)',\n",
       " 'contents': [{'type': 'speak',\n",
       "   'image': None,\n",
       "   'text': 'ì•ˆë…•í•˜ì„¸ìš”ğŸ˜Š ì €ëŠ” NCS í™ˆí˜ì´ì§€ ì•ˆë‚´ ì±—ë´‡ì´ì—ìš”! NCS í™ˆí˜ì´ì§€ì— ëŒ€í•´ì„œ ì•Œë ¤ë“œë¦´ê²Œìš”! ê¶ê¸ˆí•œ ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì‹œë©´ ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•´ë“œë¦´ê²Œìš”ğŸ˜‰',\n",
       "   'button': []}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input = \"ì•ˆë…•í•˜ì„¸ìš”!\"\n",
    "res = await chatbot_engine.chat(user_input, MAX_INFERENCE_BOUND, MIN_INFERENCE_BOUND, FALLBACK_TEXT, MULTI_INTENTS_TEXT, ERROR_TEXT)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fb458eb91b64e6da799ede2a29531a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f4690a0a49b4a6587886875866062e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 19798 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mc:\\ayeonul\\.GPT\\auto-chatbot-maker\\backend\\test.ipynb ì…€ 3\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/ayeonul/.GPT/auto-chatbot-maker/backend/test.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m data \u001b[39m=\u001b[39m [\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/ayeonul/.GPT/auto-chatbot-maker/backend/test.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     {\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/ayeonul/.GPT/auto-chatbot-maker/backend/test.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcode\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m1\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/ayeonul/.GPT/auto-chatbot-maker/backend/test.ipynb#W2sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     },\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/ayeonul/.GPT/auto-chatbot-maker/backend/test.ipynb#W2sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m ]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/ayeonul/.GPT/auto-chatbot-maker/backend/test.ipynb#W2sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m greeting_text \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mì•ˆë…•í•˜ì„¸ìš”ğŸ˜Š ì €ëŠ” ë¶€ì‚°ê³¼í•™ê¸°ìˆ ëŒ€í•™êµ AIì†Œí”„íŠ¸ì›¨ì–´í•™ê³¼ ì•ˆë‚´ ì±—ë´‡ì´ì—ìš”! AIì†Œí”„íŠ¸ì›¨ì–´í•™ê³¼ì— ëŒ€í•´ì„œ ì•Œë ¤ë“œë¦´ê²Œìš”! ê¶ê¸ˆí•œ ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì‹œë©´ ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•´ë“œë¦´ê²Œìš”ğŸ˜‰\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/ayeonul/.GPT/auto-chatbot-maker/backend/test.ipynb#W2sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m ChatbotMaker(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/ayeonul/.GPT/auto-chatbot-maker/backend/test.ipynb#W2sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     model_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgpt-3.5-turbo-1106\u001b[39;49m\u001b[39m\"\u001b[39;49m, chatbot_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39më¶€ì‚°ê³¼í•™ê¸°ìˆ ëŒ€í•™êµ AIì†Œí”„íŠ¸ì›¨ì–´í•™ê³¼ ì•ˆë‚´ ì±—ë´‡\u001b[39;49m\u001b[39m\"\u001b[39;49m, sitemap\u001b[39m=\u001b[39;49mdata, greeting_text\u001b[39m=\u001b[39;49mgreeting_text\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/ayeonul/.GPT/auto-chatbot-maker/backend/test.ipynb#W2sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\ayeonul\\.GPT\\auto-chatbot-maker\\backend\\utils.py:280\u001b[0m, in \u001b[0;36mChatbotMaker.__init__\u001b[1;34m(self, model_name, chatbot_name, sitemap, greeting_text)\u001b[0m\n\u001b[0;32m    273\u001b[0m                 \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    274\u001b[0m                     prompt \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\"\"\u001b[39m\u001b[39mBelow is the \u001b[39m\u001b[39m{\u001b[39;00mitem\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m for \u001b[39m\u001b[39m{\u001b[39;00mchatbot_name\u001b[39m}\u001b[39;00m\u001b[39m. web page (or pages) contents.\u001b[39m\n\u001b[0;32m    275\u001b[0m \n\u001b[0;32m    276\u001b[0m \u001b[39m{\u001b[39;00mweb_text\u001b[39m}\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \u001b[39m---\u001b[39m\n\u001b[0;32m    278\u001b[0m \u001b[39mRegardless of the content of the webpage, provide the summary in a polite tone like a information chatbot.\u001b[39m\n\u001b[0;32m    279\u001b[0m \u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m--> 280\u001b[0m                 gpt_res \u001b[39m=\u001b[39m creater([{\u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: prompt}])\n\u001b[0;32m    281\u001b[0m                 content[\u001b[39m\"\u001b[39m\u001b[39mcontents\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m gpt_res[\u001b[39m\"\u001b[39m\u001b[39mres\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mres\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    283\u001b[0m             chatbot_contents\u001b[39m.\u001b[39mappend(content)\n",
      "File \u001b[1;32mc:\\Users\\2210B\\miniforge3\\envs\\main\\lib\\site-packages\\tenacity\\__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[1;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(f, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n",
      "File \u001b[1;32mc:\\Users\\2210B\\miniforge3\\envs\\main\\lib\\site-packages\\tenacity\\__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[0;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\2210B\\miniforge3\\envs\\main\\lib\\site-packages\\tenacity\\__init__.py:325\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    323\u001b[0m     retry_exc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretry_error_cls(fut)\n\u001b[0;32m    324\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreraise:\n\u001b[1;32m--> 325\u001b[0m         \u001b[39mraise\u001b[39;00m retry_exc\u001b[39m.\u001b[39;49mreraise()\n\u001b[0;32m    326\u001b[0m     \u001b[39mraise\u001b[39;00m retry_exc \u001b[39mfrom\u001b[39;00m \u001b[39mfut\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexception\u001b[39;00m()\n\u001b[0;32m    328\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwait:\n",
      "File \u001b[1;32mc:\\Users\\2210B\\miniforge3\\envs\\main\\lib\\site-packages\\tenacity\\__init__.py:158\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreraise\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mNoReturn:\n\u001b[0;32m    157\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_attempt\u001b[39m.\u001b[39mfailed:\n\u001b[1;32m--> 158\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlast_attempt\u001b[39m.\u001b[39;49mresult()\n\u001b[0;32m    159\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\2210B\\miniforge3\\envs\\main\\lib\\concurrent\\futures\\_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    437\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    438\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m--> 439\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[0;32m    441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[0;32m    443\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\2210B\\miniforge3\\envs\\main\\lib\\concurrent\\futures\\_base.py:391\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[0;32m    390\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 391\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[0;32m    392\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    393\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    394\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\2210B\\miniforge3\\envs\\main\\lib\\site-packages\\tenacity\\__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    381\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 382\u001b[0m         result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    383\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n\u001b[0;32m    384\u001b[0m         retry_state\u001b[39m.\u001b[39mset_exception(sys\u001b[39m.\u001b[39mexc_info())  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ayeonul\\.GPT\\auto-chatbot-maker\\backend\\GPT.py:73\u001b[0m, in \u001b[0;36mChatGPT.chat\u001b[1;34m(self, messages, n)\u001b[0m\n\u001b[0;32m     66\u001b[0m gpt_args \u001b[39m=\u001b[39m {\n\u001b[0;32m     67\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel,\n\u001b[0;32m     68\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m: prompt,\n\u001b[0;32m     69\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mn\u001b[39m\u001b[39m\"\u001b[39m: n,\n\u001b[0;32m     70\u001b[0m }\n\u001b[0;32m     71\u001b[0m gpt_args\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgpt_opt)\n\u001b[1;32m---> 73\u001b[0m gpt_response, token_info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_gpt_res(gpt_args)\n\u001b[0;32m     74\u001b[0m res \u001b[39m=\u001b[39m []\n\u001b[0;32m     75\u001b[0m \u001b[39mfor\u001b[39;00m gpt_res \u001b[39min\u001b[39;00m gpt_response:\n",
      "File \u001b[1;32mc:\\ayeonul\\.GPT\\auto-chatbot-maker\\backend\\GPT.py:39\u001b[0m, in \u001b[0;36mChatGPT.get_gpt_res\u001b[1;34m(self, gpt_args)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_gpt_res\u001b[39m(\u001b[39mself\u001b[39m, gpt_args: \u001b[39mdict\u001b[39m):\n\u001b[0;32m     31\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[39m    OpenAIì— ì‹¤ì œë¡œ ìš”ì²­ ë³´ë‚´ê³  ì‘ë‹µ ë°›ëŠ” í•¨ìˆ˜. choicesì˜ result listì™€ token ì‚¬ìš© ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[39m    - Attributes\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[39m        - int: chat tokensì™€ completion tokensë¥¼ ëª¨ë‘ í•©í•œ total tokensë§Œì„ ê°€ì ¸ì˜µë‹ˆë‹¤. statefulí•œ ë†ˆì„ ë§Œë“¤ ë•Œ í† í° ì œì–´ìš©ìœ¼ë¡œ ì‚¬ìš©í•˜ì„¸ìš©.\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m     gpt_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mchat\u001b[39m.\u001b[39mcompletions\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mgpt_args)\n\u001b[0;32m     40\u001b[0m     res_msg \u001b[39m=\u001b[39m gpt_response\u001b[39m.\u001b[39mchoices\n\u001b[0;32m     41\u001b[0m     token_info \u001b[39m=\u001b[39m gpt_response\u001b[39m.\u001b[39musage\u001b[39m.\u001b[39mtotal_tokens\n",
      "File \u001b[1;32mc:\\Users\\2210B\\miniforge3\\envs\\main\\lib\\site-packages\\openai\\_utils\\_utils.py:299\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    297\u001b[0m             msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMissing required argument: \u001b[39m\u001b[39m{\u001b[39;00mquote(missing[\u001b[39m0\u001b[39m])\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    298\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 299\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\2210B\\miniforge3\\envs\\main\\lib\\site-packages\\openai\\resources\\chat\\completions.py:594\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    548\u001b[0m \u001b[39m@required_args\u001b[39m([\u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m], [\u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m    549\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    550\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    592\u001b[0m     timeout: \u001b[39mfloat\u001b[39m \u001b[39m|\u001b[39m httpx\u001b[39m.\u001b[39mTimeout \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m|\u001b[39m NotGiven \u001b[39m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    593\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ChatCompletion \u001b[39m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m--> 594\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_post(\n\u001b[0;32m    595\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39m/chat/completions\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    596\u001b[0m         body\u001b[39m=\u001b[39;49mmaybe_transform(\n\u001b[0;32m    597\u001b[0m             {\n\u001b[0;32m    598\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmessages\u001b[39;49m\u001b[39m\"\u001b[39;49m: messages,\n\u001b[0;32m    599\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmodel\u001b[39;49m\u001b[39m\"\u001b[39;49m: model,\n\u001b[0;32m    600\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfrequency_penalty\u001b[39;49m\u001b[39m\"\u001b[39;49m: frequency_penalty,\n\u001b[0;32m    601\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfunction_call\u001b[39;49m\u001b[39m\"\u001b[39;49m: function_call,\n\u001b[0;32m    602\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfunctions\u001b[39;49m\u001b[39m\"\u001b[39;49m: functions,\n\u001b[0;32m    603\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mlogit_bias\u001b[39;49m\u001b[39m\"\u001b[39;49m: logit_bias,\n\u001b[0;32m    604\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmax_tokens\u001b[39;49m\u001b[39m\"\u001b[39;49m: max_tokens,\n\u001b[0;32m    605\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mn\u001b[39;49m\u001b[39m\"\u001b[39;49m: n,\n\u001b[0;32m    606\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mpresence_penalty\u001b[39;49m\u001b[39m\"\u001b[39;49m: presence_penalty,\n\u001b[0;32m    607\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mresponse_format\u001b[39;49m\u001b[39m\"\u001b[39;49m: response_format,\n\u001b[0;32m    608\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mseed\u001b[39;49m\u001b[39m\"\u001b[39;49m: seed,\n\u001b[0;32m    609\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstop\u001b[39;49m\u001b[39m\"\u001b[39;49m: stop,\n\u001b[0;32m    610\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstream\u001b[39;49m\u001b[39m\"\u001b[39;49m: stream,\n\u001b[0;32m    611\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtemperature\u001b[39;49m\u001b[39m\"\u001b[39;49m: temperature,\n\u001b[0;32m    612\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtool_choice\u001b[39;49m\u001b[39m\"\u001b[39;49m: tool_choice,\n\u001b[0;32m    613\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtools\u001b[39;49m\u001b[39m\"\u001b[39;49m: tools,\n\u001b[0;32m    614\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtop_p\u001b[39;49m\u001b[39m\"\u001b[39;49m: top_p,\n\u001b[0;32m    615\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m: user,\n\u001b[0;32m    616\u001b[0m             },\n\u001b[0;32m    617\u001b[0m             completion_create_params\u001b[39m.\u001b[39;49mCompletionCreateParams,\n\u001b[0;32m    618\u001b[0m         ),\n\u001b[0;32m    619\u001b[0m         options\u001b[39m=\u001b[39;49mmake_request_options(\n\u001b[0;32m    620\u001b[0m             extra_headers\u001b[39m=\u001b[39;49mextra_headers, extra_query\u001b[39m=\u001b[39;49mextra_query, extra_body\u001b[39m=\u001b[39;49mextra_body, timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[0;32m    621\u001b[0m         ),\n\u001b[0;32m    622\u001b[0m         cast_to\u001b[39m=\u001b[39;49mChatCompletion,\n\u001b[0;32m    623\u001b[0m         stream\u001b[39m=\u001b[39;49mstream \u001b[39mor\u001b[39;49;00m \u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    624\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mStream[ChatCompletionChunk],\n\u001b[0;32m    625\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\2210B\\miniforge3\\envs\\main\\lib\\site-packages\\openai\\_base_client.py:1055\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1041\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(\n\u001b[0;32m   1042\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   1043\u001b[0m     path: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1050\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1051\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[0;32m   1052\u001b[0m     opts \u001b[39m=\u001b[39m FinalRequestOptions\u001b[39m.\u001b[39mconstruct(\n\u001b[0;32m   1053\u001b[0m         method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m, url\u001b[39m=\u001b[39mpath, json_data\u001b[39m=\u001b[39mbody, files\u001b[39m=\u001b[39mto_httpx_files(files), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions\n\u001b[0;32m   1054\u001b[0m     )\n\u001b[1;32m-> 1055\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(ResponseT, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(cast_to, opts, stream\u001b[39m=\u001b[39;49mstream, stream_cls\u001b[39m=\u001b[39;49mstream_cls))\n",
      "File \u001b[1;32mc:\\Users\\2210B\\miniforge3\\envs\\main\\lib\\site-packages\\openai\\_base_client.py:834\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    825\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    826\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    827\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    832\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    833\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[1;32m--> 834\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[0;32m    835\u001b[0m         cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[0;32m    836\u001b[0m         options\u001b[39m=\u001b[39;49moptions,\n\u001b[0;32m    837\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    838\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[0;32m    839\u001b[0m         remaining_retries\u001b[39m=\u001b[39;49mremaining_retries,\n\u001b[0;32m    840\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\2210B\\miniforge3\\envs\\main\\lib\\site-packages\\openai\\_base_client.py:877\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    874\u001b[0m     \u001b[39m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m    875\u001b[0m     \u001b[39m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m    876\u001b[0m     err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mread()\n\u001b[1;32m--> 877\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_status_error_from_response(err\u001b[39m.\u001b[39mresponse) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[39mexcept\u001b[39;00m httpx\u001b[39m.\u001b[39mTimeoutException \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    879\u001b[0m     \u001b[39mif\u001b[39;00m retries \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[1;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 19798 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    {\n",
    "        \"code\": \"1\",\n",
    "        \"title\": \"í•™ê³¼ ì†Œê°œ\",\n",
    "        \"url\": [\"http://computer.bist.ac.kr/contents/contents_view.php?site_id=computer&TREE_NO=1656&DEPTH=3\",\n",
    "                \"http://computer.bist.ac.kr/contents/contents_view.php?site_id=computer&TREE_NO=1657&DEPTH=3\"],\n",
    "    },\n",
    "    {\n",
    "        \"code\": \"2\",\n",
    "        \"title\": \"êµìˆ˜ ì†Œê°œ\",\n",
    "        \"url\": [\"http://computer.bist.ac.kr/professor/list.php?site_id=computer&TREE_NO=1579&DEPTH=2\",\n",
    "                \"http://computer.bist.ac.kr/professor/view.php?site_id=computer&TREE_NO=1579&DEPTH=2&idx=118\",\n",
    "                \"http://computer.bist.ac.kr/professor/view.php?site_id=computer&TREE_NO=1579&DEPTH=2&idx=89\",\n",
    "                \"http://computer.bist.ac.kr/professor/view.php?site_id=computer&TREE_NO=1579&DEPTH=2&idx=514\"],\n",
    "    },\n",
    "    {\n",
    "        \"code\": \"3\",\n",
    "        \"title\": \"êµìœ¡ê³¼ì •\",\n",
    "        \"url\": [\"http://computer.bist.ac.kr/contents/contents_view.php?site_id=computer&TREE_NO=1658&DEPTH=3\",\n",
    "                \"http://computer.bist.ac.kr/contents/contents_view.php?site_id=computer&TREE_NO=1660&DEPTH=3\",\n",
    "                \"http://computer.bist.ac.kr/contents/contents_view.php?site_id=computer&TREE_NO=1664&DEPTH=3\"],\n",
    "    },\n",
    "    {\n",
    "        \"code\": \"4\",\n",
    "        \"title\": \"í•™ê³¼ì‹œì„¤\",\n",
    "        \"url\": [\"http://computer.bist.ac.kr/contents/contents_view.php?site_id=computer&TREE_NO=1582&DEPTH=2\"],\n",
    "    },\n",
    "]\n",
    "\n",
    "greeting_text = \"ì•ˆë…•í•˜ì„¸ìš”ğŸ˜Š ì €ëŠ” ë¶€ì‚°ê³¼í•™ê¸°ìˆ ëŒ€í•™êµ AIì†Œí”„íŠ¸ì›¨ì–´í•™ê³¼ ì•ˆë‚´ ì±—ë´‡ì´ì—ìš”! AIì†Œí”„íŠ¸ì›¨ì–´í•™ê³¼ì— ëŒ€í•´ì„œ ì•Œë ¤ë“œë¦´ê²Œìš”! ê¶ê¸ˆí•œ ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì‹œë©´ ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•´ë“œë¦´ê²Œìš”ğŸ˜‰\"\n",
    "\n",
    "ChatbotMaker(\n",
    "    model_name=\"gpt-3.5-turbo-1106\", chatbot_name=\"ë¶€ì‚°ê³¼í•™ê¸°ìˆ ëŒ€í•™êµ AIì†Œí”„íŠ¸ì›¨ì–´í•™ê³¼ ì•ˆë‚´ ì±—ë´‡\", sitemap=data, greeting_text=greeting_text\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ayeonul",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
